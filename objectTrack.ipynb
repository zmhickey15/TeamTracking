{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zmhickey/Footballnotebooks/TeamTracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.9.16 torch-1.13.0 CPU\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 321.3/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolox.__version__: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!git clone https://github.com/ifzhang/ByteTrack.git\n",
    "%cd {HOME}/ByteTrack\n",
    "\n",
    "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
    "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
    "\n",
    "!pip3 install -q -r requirements.txt\n",
    "!python3 setup.py -q develop\n",
    "!pip install -q cython_bbox\n",
    "!pip install -q onemetric\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/ByteTrack\")\n",
    "\n",
    "\n",
    "import yolox\n",
    "print(\"yolox.__version__:\", yolox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
    "from onemetric.cv.utils.iou import box_iou_batch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25\n",
    "    track_buffer: int = 30\n",
    "    match_thresh: float = 0.8\n",
    "    aspect_ratio_thresh: float = 3.0\n",
    "    min_box_area: float = 1.0\n",
    "    mot20: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision.__version__: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install supervision==0.1.0\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import supervision\n",
    "print(\"supervision.__version__:\", supervision.__version__)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.geometry.dataclasses import Point\n",
    "from supervision.video.dataclasses import VideoInfo\n",
    "from supervision.video.source import get_video_frames_generator\n",
    "from supervision.video.sink import VideoSink\n",
    "from supervision.notebook.utils import show_frame_in_notebook\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
    "def detections2boxes(detections: Detections) -> np.ndarray:\n",
    "    return np.hstack((\n",
    "        detections.xyxy,\n",
    "        detections.confidence[:, np.newaxis]\n",
    "    ))\n",
    "\n",
    "\n",
    "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
    "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
    "    return np.array([\n",
    "        track.tlbr\n",
    "        for track\n",
    "        in tracks\n",
    "    ], dtype=float)\n",
    "\n",
    "\n",
    "# matches our bounding boxes with predictions\n",
    "def match_detections_with_tracks(\n",
    "    detections: Detections, \n",
    "    tracks: List[STrack]\n",
    ") -> Detections:\n",
    "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
    "        return np.empty((0,))\n",
    "\n",
    "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
    "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
    "    track2detection = np.argmax(iou, axis=1)\n",
    "    \n",
    "    tracker_ids = [None] * len(detections)\n",
    "    \n",
    "    for tracker_index, detection_index in enumerate(track2detection):\n",
    "        if iou[tracker_index, detection_index] != 0:\n",
    "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
    "\n",
    "    return tracker_ids\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = f\"{HOME}/runs/detect/train/weights/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Model summary (fused): 168 layers, 11128293 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(WEIGHTS_PATH)\n",
    "model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict maping class_id to class_name\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "# class_ids of interest - car, motorcycle, bus and truck\n",
    "CLASS_ID = [0, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH=f\"{HOME}/datasets/video3.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# create instance of BoxAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "# acquire first video frame\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "# model prediction on single frame and conversion to supervision Detections\n",
    "results = model(frame)\n",
    "detections = Detections(\n",
    "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    ")\n",
    "# format custom labels\n",
    "labels = [\n",
    "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for _, confidence, class_id, tracker_id\n",
    "    in detections\n",
    "]\n",
    "# annotate and display frame\n",
    "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "show_frame_in_notebook(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=30, total_frames=432)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_VIDEO_PATH = f\"{HOME}/v3Results.mp4\"\n",
    "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# create BYTETracker instance\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
    "# create VideoInfo instance\n",
    "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# create LineCounter instance\n",
    "# create instance of BoxAnnotator and LineCounterAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "\n",
    "# open target video file\n",
    "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "    # loop over video frames\n",
    "    for frame in tqdm(generator, total=video_info.total_frames):\n",
    "        # model prediction on single frame and conversion to supervision Detections\n",
    "        results = model(frame)\n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        # filtering out detections with unwanted classes\n",
    "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # tracking detections\n",
    "        tracks = byte_tracker.update(\n",
    "            output_results=detections2boxes(detections=detections),\n",
    "            img_info=frame.shape,\n",
    "            img_size=frame.shape\n",
    "        )\n",
    "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "        detections.tracker_id = np.array(tracker_id)\n",
    "        # filtering out detections without trackers\n",
    "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # format custom labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "            for _, confidence, class_id, tracker_id\n",
    "            in detections\n",
    "        ]\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "        sink.write_frame(frame)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "\n",
    "\n",
    "# create BYTETracker instance\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
    "# create VideoInfo instance\n",
    "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# create LineCounter instance\n",
    "# create instance of BoxAnnotator and LineCounterAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=1, text_thickness=1, text_scale=.5)\n",
    "\n",
    "\n",
    "# open target video file\n",
    "TeamInPos = 0\n",
    "Team1TotalPos = 0\n",
    "Team2TotalPos = 0\n",
    "TotalTime = 0\n",
    "\n",
    "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "    # loop over video frames\n",
    "    for frame in tqdm(generator, total=video_info.total_frames):\n",
    "        # model prediction on single frame and conversion to supervision Detections\n",
    "        results = model.predict(frame)\n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        # filtering out detections with unwanted classes\n",
    "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # tracking detections\n",
    "        tracks = byte_tracker.update(\n",
    "            output_results=detections2boxes(detections=detections),\n",
    "            img_info=frame.shape,\n",
    "            img_size=frame.shape\n",
    "        )\n",
    "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "        detections.tracker_id = np.array(tracker_id)\n",
    "        \n",
    "        # filtering out detections without trackers\n",
    "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "        #detections.filter(mask=mask, inplace=True) #this gets rid of some of the things ie ball go away\n",
    "        \n",
    "        # format custom labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "            for _, confidence, class_id, tracker_id\n",
    "            in detections\n",
    "        ]\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "        \n",
    "        # check ball pos\n",
    "        \n",
    "        ballFound = False \n",
    "        for detection in detections:\n",
    "            #print(detection[0])\n",
    "            x  = (detection[0][0] + detection[0][1]) / 2\n",
    "            y = (detection[0][2] + detection[0][3]) / 2\n",
    "            ballPos = np.array( [x,y])\n",
    "            \n",
    "            #print(ballPos)\n",
    "            # ball\n",
    "            if(detection[2] == 0):\n",
    "                #print('ball found')\n",
    "                ballPos = np.array([ (detection[0][0] + detection[0][1]) / 2, (detection[0][2] + detection[0][3]) / 2 ])\n",
    "                ballFound = True\n",
    "                #print(ballPos)\n",
    "            # team 1\n",
    "            players = []\n",
    "            if(detection[2] == 4):\n",
    "                x  = (detection[0][0] + detection[0][1]) / 2\n",
    "                y = (detection[0][2] + detection[0][3]) / 2\n",
    "                players.append([4,x,y])\n",
    "            # team 2\n",
    "            if(detection[2] == 5):\n",
    "                x  = (detection[0][0] + detection[0][1]) / 2\n",
    "                y = (detection[0][2] + detection[0][3]) / 2\n",
    "                players.append([5,x,y])           \n",
    "            players = np.array(players)\n",
    "            \n",
    "            #check team in pos\n",
    "            Team1Pos = False\n",
    "            Team2Pos = False\n",
    "            if(ballFound):\n",
    "                for player in players:\n",
    "                    dist = math.sqrt((ballPos[0] - player[1])**2 + (ballPos[1] - player[2])**2)\n",
    "                    if(dist < 30):\n",
    "                        if(player[0] == 4):\n",
    "                            Team1Pos = True\n",
    "                        else: \n",
    "                            Team2Pos = True\n",
    "            # check who has the ball\n",
    "            if(Team1Pos and Team2Pos):\n",
    "                TeamInPos = 0\n",
    "            elif(Team1Pos):\n",
    "                TeamInPos = 1\n",
    "            elif(Team2Pos):\n",
    "                TeamInPos = 2\n",
    "            # increment team in pos and total time\n",
    "            if(TeamInPos == 1):\n",
    "                Team1TotalPos += 1\n",
    "            if(TeamInPos == 2):\n",
    "                Team2TotalPos += 1\n",
    "            TotalTime +=1\n",
    "\n",
    "            #create bar with pos \n",
    "            color = (255, 0, 0) \n",
    "            x, y, h = 100, 100, 20\n",
    "            T1curAmount = (Team1TotalPos/TotalTime)\n",
    "            inCostCuramount = (TotalTime - Team1TotalPos - Team2TotalPos)/TotalTime\n",
    "            T2curamount = (TotalTime - Team1TotalPos - Team2TotalPos)/TotalTime\n",
    "            x1 = 100 + int(600 *T1curAmount)\n",
    "            x2 = x1 + int(600 * inCostCuramount)\n",
    "            #team1\n",
    "            color = (255, 0, 0) \n",
    "            cv2.rectangle(frame, (x, 100), (x1, 120), color, thickness=-1)\n",
    "\n",
    "            #incontest\n",
    "            color = (0, 225, 0) \n",
    "            cv2.rectangle(frame, (x1, 100), (x2, 120), color, thickness=-1)\n",
    "\n",
    "            #team2\n",
    "            color = (0, 0, 225) \n",
    "            cv2.rectangle(frame, (x2, 100), (600, 120), color, thickness=-1)\n",
    "\n",
    "\n",
    "        sink.write_frame(frame)\n",
    "#prints pos of teams\n",
    "print('team1 pos: ' , 100 * (Team1TotalPos/TotalTime) )\n",
    "print('team2 pos: ' , 100 * (Team2TotalPos/TotalTime))\n",
    "print('inContest: ', 100 * ((TotalTime - Team1TotalPos - Team2TotalPos)/TotalTime) )\n",
    "print('total time: ', TotalTime )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4c5df7bc827e4757c89086aa17e48b1fa763b5734ea8cedcdea2db21b6c25ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
