{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zmhickey/Footballnotebooks/TeamTracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.9.16 torch-1.13.0 CPU\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 321.3/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolox.__version__: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!git clone https://github.com/ifzhang/ByteTrack.git\n",
    "%cd {HOME}/ByteTrack\n",
    "\n",
    "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
    "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
    "\n",
    "!pip3 install -q -r requirements.txt\n",
    "!python3 setup.py -q develop\n",
    "!pip install -q cython_bbox\n",
    "!pip install -q onemetric\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/ByteTrack\")\n",
    "\n",
    "\n",
    "import yolox\n",
    "print(\"yolox.__version__:\", yolox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
    "from onemetric.cv.utils.iou import box_iou_batch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25\n",
    "    track_buffer: int = 30\n",
    "    match_thresh: float = 0.8\n",
    "    aspect_ratio_thresh: float = 3.0\n",
    "    min_box_area: float = 1.0\n",
    "    mot20: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision.__version__: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install supervision==0.1.0\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import supervision\n",
    "print(\"supervision.__version__:\", supervision.__version__)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.geometry.dataclasses import Point\n",
    "from supervision.video.dataclasses import VideoInfo\n",
    "from supervision.video.source import get_video_frames_generator\n",
    "from supervision.video.sink import VideoSink\n",
    "from supervision.notebook.utils import show_frame_in_notebook\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
    "def detections2boxes(detections: Detections) -> np.ndarray:\n",
    "    return np.hstack((\n",
    "        detections.xyxy,\n",
    "        detections.confidence[:, np.newaxis]\n",
    "    ))\n",
    "\n",
    "\n",
    "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
    "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
    "    return np.array([\n",
    "        track.tlbr\n",
    "        for track\n",
    "        in tracks\n",
    "    ], dtype=float)\n",
    "\n",
    "\n",
    "# matches our bounding boxes with predictions\n",
    "def match_detections_with_tracks(\n",
    "    detections: Detections, \n",
    "    tracks: List[STrack]\n",
    ") -> Detections:\n",
    "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
    "        return np.empty((0,))\n",
    "\n",
    "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
    "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
    "    track2detection = np.argmax(iou, axis=1)\n",
    "    \n",
    "    tracker_ids = [None] * len(detections)\n",
    "    \n",
    "    for tracker_index, detection_index in enumerate(track2detection):\n",
    "        if iou[tracker_index, detection_index] != 0:\n",
    "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
    "\n",
    "    return tracker_ids\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = f\"{HOME}/runs/detect/train/weights/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Model summary (fused): 168 layers, 11128293 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(WEIGHTS_PATH)\n",
    "model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict maping class_id to class_name\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "# class_ids of interest - car, motorcycle, bus and truck\n",
    "CLASS_ID = [0, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH=f\"{HOME}/datasets/video3.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# create instance of BoxAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "# acquire first video frame\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "# model prediction on single frame and conversion to supervision Detections\n",
    "results = model(frame)\n",
    "detections = Detections(\n",
    "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    ")\n",
    "# format custom labels\n",
    "labels = [\n",
    "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for _, confidence, class_id, tracker_id\n",
    "    in detections\n",
    "]\n",
    "# annotate and display frame\n",
    "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "show_frame_in_notebook(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=30, total_frames=432)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_VIDEO_PATH = f\"{HOME}/v3Results.mp4\"\n",
    "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# create BYTETracker instance\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
    "# create VideoInfo instance\n",
    "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# create LineCounter instance\n",
    "# create instance of BoxAnnotator and LineCounterAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "\n",
    "# open target video file\n",
    "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "    # loop over video frames\n",
    "    for frame in tqdm(generator, total=video_info.total_frames):\n",
    "        # model prediction on single frame and conversion to supervision Detections\n",
    "        results = model(frame)\n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        # filtering out detections with unwanted classes\n",
    "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # tracking detections\n",
    "        tracks = byte_tracker.update(\n",
    "            output_results=detections2boxes(detections=detections),\n",
    "            img_info=frame.shape,\n",
    "            img_size=frame.shape\n",
    "        )\n",
    "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "        detections.tracker_id = np.array(tracker_id)\n",
    "        # filtering out detections without trackers\n",
    "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # format custom labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "            for _, confidence, class_id, tracker_id\n",
    "            in detections\n",
    "        ]\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "        sink.write_frame(frame)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4c5df7bc827e4757c89086aa17e48b1fa763b5734ea8cedcdea2db21b6c25ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
